{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransferLearning_TensorFlow.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5akULiddp4s-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning\n",
        "Transfer Learning a technique which is used to get the advantage of other pre_trained models in order to save time and help us in computation process.\n",
        "the 2nd advantage is the accuracy, as we are not having access to wide variety of data to learn the parameters from, we might face overfitting in our model, by taking the advantage of transfer learning,which had trained on 1000s of images, we can increase the validation and training accuracy of our model.\n",
        "\n",
        "# Inception V.3\n",
        "It is an images recognition model which has beeen shown to attain greater than 78.1 % accuracy on imageNet dataset. this model itself builds upon pooling layers,Dense layers, activation funcitons,fully connected layers and so on.\n",
        " This model can classify images into 1000 categories,"
      ],
      "metadata": {
        "id": "KhSw_lylteHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the pre-trained weights. No top means it excludes the fully connected layer it uses for classification.\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "    "
      ],
      "metadata": {
        "id": "Diklh0UJut5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Freezing and importing the inception model.\n",
        "the main idea behind the freezing is to avoid retraining the pretrained weightts which we have already downloaded.\n",
        "as we are going to add our dense layer to the end of some layer of the pretrained inception network layers, we will remove the last fully connected layer,because we will add our own layer at the end.\n",
        "\n",
        "from model.summary(), we can observe the operations and parameters, we also can select till the which part of the network we want to use,for exampel here will use up to mixed_8 layer.\n",
        "\n",
        "## Note:\n",
        "Remember that the as much as we go deeper inside the network, that much our layers are going to get specific and specialized about the features"
      ],
      "metadata": {
        "id": "0x1IswDW_0zP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uHUq0JrT9Nyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the models\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# set the weights file which we have downloaded in previous layer into a variable\n",
        "weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "# define the base model,set the input shape and remove the dense layer\n",
        "pre_trained_model = InceptionV3(input_shape=(150,150,3),\n",
        "                                include_top = False,\n",
        "                                weights = None) \n",
        "# load the pre_trained weights in to the model\n",
        "pre_trained_model.load_weights(weights_file)\n",
        "\n",
        "# Freeze the weights\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# pre_trained_model.summary()"
      ],
      "metadata": {
        "id": "Jtv1kldsuxAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose the last layer, as mentioned before, we are going with mixed_8 layer"
      ],
      "metadata": {
        "id": "_ke1xw0kJTK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_pre_trained_layer = pre_trained_model.get_layer('mixed8')\n",
        "print('last layer output shape: ', last_pre_trained_layer.output_shape)\n",
        "last_output = last_pre_trained_layer.output"
      ],
      "metadata": {
        "id": "XRgtZV0wBDB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add Dense layer to the network,\n",
        " Here by Dense layer we mean the layer we want to add from our side.\n"
      ],
      "metadata": {
        "id": "lqK_w1xYJ2Lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "\n",
        "# Flatten the output layer to 1 dimension( the mixed8 one )\n",
        "last_layer = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "last_layer = layers.Dense(1280,activation=\"relu\")(last_layer)\n",
        "# Add a dropout rate of 0.3\n",
        "last_layer = layers.Dropout(0.3)(last_layer)\n",
        "# Add a sigmoid function to classify the image after the Dense layer\n",
        "last_layer = layers.Dense(1,activation=\"sigmoid\")(last_layer)\n",
        "# Append the Dense network to the base(pre_trained_model) model, this Dense network have been introduced by us.!\n",
        "model = Model(pre_trained_model.input,last_layer)\n",
        "# model.summary()\n"
      ],
      "metadata": {
        "id": "vtemDmWGJwwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the parameters like, loss,optimizer and metrics for training"
      ],
      "metadata": {
        "id": "UG7U2f4wODAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "USlcM4etN6AO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer = tf.keras.optimizers.Adam(),\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "dez0jFSUKJdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the data set\n",
        "we are going to use the Imageprocessing technique to process our data and flow it frow our specific directories,and alse on the fly we will rescale and augment all the iamges before feeding into the network, the purpose of this is to avoid overfitting and introduce new variety of pictures."
      ],
      "metadata": {
        "id": "fo2PGEZqOsce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "!wget https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip"
      ],
      "metadata": {
        "id": "H76PtOzaOj76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.gen_batch_ops import batch\n",
        "import os \n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# Extract the archive\n",
        "path = \"./cats_and_dogs_filtered.zip\"\n",
        "zip_ref = zipfile.ZipFile(path,'r')\n",
        "zip_ref.extractall('tmp/')\n",
        "zip_ref.close()\n",
        "\n",
        "# Defining our base directory\n",
        "\n",
        "base_dir = 'tmp/cats_and_dogs_filtered'\n",
        "\n",
        "train_dir = os.path.join(base_dir,\"train\")\n",
        "validation_dir = os.path.join(base_dir,'validation')\n",
        "\n",
        "# directory with training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir,'cats')\n",
        "# direcctory with training dogs\n",
        "train_dogs_dir = os.path.join(train_dir,'dogs')\n",
        "# directory with validation cat pictures\n",
        "val_cats_dir = os.path.join(validation_dir,'cats')\n",
        "# directory with validation dog pictures\n",
        "val_dogs_dir = os.path.join(validation_dir,\"dogs\")\n",
        "\n",
        "# Using ImageDataGenerator to augment and rescale our image on the fly(while we are flowing data,IDG will do the processing simultaneously)\n",
        "Train_DataGenerator = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "# Validation data should not be augmented as we are checking the goodness of our model while training with this.\n",
        "Val_DataGenerator = ImageDataGenerator(rescale = 1./255.)\n",
        "# Flowing the training data from directory, targrt_size means that we might have different sizes of images,so we want all in one size.\n",
        "Training_Data = Train_DataGenerator.flow_from_directory(train_dir,\n",
        "                                                        batch_size = 20,\n",
        "                                                        class_mode = 'binary',\n",
        "                                                        target_size=(150,150))\n",
        "# Flowing validation data\n",
        "Validation_Data = Val_DataGenerator.flow_from_directory(validation_dir,\n",
        "                                                        batch_size = 20,\n",
        "                                                        class_mode = 'binary',\n",
        "                                                        target_size = (150,150))\n",
        "\n"
      ],
      "metadata": {
        "id": "hKBP3RBwPXH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model\n"
      ],
      "metadata": {
        "id": "QrUcU_nFYPNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(Training_Data,\n",
        "                    epochs = 10,\n",
        "                    validation_data = Validation_Data,\n",
        "                    verbose  = 2)"
      ],
      "metadata": {
        "id": "d49mIvNDTqjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Note\n",
        "the fit() method returns a History object containing the traning parameters(histoty.params),the list of epohcs it went through(history.epoch), and importantly a dictionary (history.history) containing the loss and extra metrics it measured at the end of each epoch on the training set and validation set."
      ],
      "metadata": {
        "id": "uHjvEAJxbtPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VcSPVWk3ckwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot the accuracy and loss of our model"
      ],
      "metadata": {
        "id": "UekLjzQZY86X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(accuracy))\n",
        "\n",
        "plt.plot(epochs,accuracy,'r',label = 'Training_accuracy')\n",
        "plt.plot(epochs,val_accuracy,'g',label = 'Validation_accuracy')\n",
        "plt.title('Validation and Traininig accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "# Plotting the loss for both training and validation data\n",
        "plt.plot(epochs,loss,'r',label = 'Training_loss')\n",
        "plt.plot(epochs,val_loss,'g',label = 'Validation_loss')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "S4hSP9WMYmi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0,1)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R7hUeT86aCD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "|"
      ],
      "metadata": {
        "id": "Hrr7PVyIaZ-G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}